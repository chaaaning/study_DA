{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part2. 예제 1번\n",
    "---\n",
    "사람 손글씨 데이터 (MNIST)를 이용해 MLP 설계하기  \n",
    "MLP 모델 설계 순서는 다음과 같음\n",
    "1. 모듈 임포트\n",
    "2. 딥러닝 모델 설계 시 활용하는 장비 확인\n",
    "3. MNIST 데이터 다운로드 (train, test split)\n",
    "4. 데이터 확인하기 (1)\n",
    "5. 데이터 확인하기 (2)\n",
    "6. MLP (Multi Layer Perceptron) 설계\n",
    "7. Optimizer, Objective Function 설정\n",
    "8. MLP 모델 학습 시 학습 데이터에 대한 모델 성능을 확인하는 함수 정의\n",
    "9. 학습 과정에서 검증 데이터에 대한 모델의 성능을 확인하는 함수 정의\n",
    "10. MLP 학습을 실행하면서 Train, Test set의 Loss 및 Test set Accuracy 확인\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.모듈 import\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''1. Module Import'''\n",
    "import numpy as np                              # numpy\n",
    "import matplotlib.pyplot as plt                 # 시각화\n",
    "import torch                                    # torch 기본 모듈\n",
    "import torch.nn as nn                           # 인공 신경망 모델 설계시 필요한 함수를 모아 놓음 (neural network)\n",
    "import torch.nn.functional as F                 # 자주 이용되는 functional 함수 \n",
    "from torchvision import transforms, datasets    # torchvision의 transforms, datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.딥러닝 모델 설계 시 장비 확인\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using PyTorch version: 1.10.1  Device: cuda\n"
     ]
    }
   ],
   "source": [
    "'''2. 딥러닝 모델을 설계할 때 활용하는 장비 확인'''\n",
    "if torch.cuda.is_available():\n",
    "    DEVICE = torch.device('cuda')\n",
    "else:\n",
    "    DEVICE = torch.device('cpu')\n",
    "print(f\"Using PyTorch version: {torch.__version__}  Device: {DEVICE}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 하이퍼 파라미터 세팅은 보통 영어 대문자로 표기\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 10"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **BATCH와 EPOCHS**\n",
    "\n",
    "---\n",
    "\n",
    "- **<span style=\"color:green\">BATCH_SIZE</span>**\n",
    "    - MLP 모델 학습 시 필요한 데이터 개수의 단위\n",
    "    - Mini-Batch 1개 단위에 대해 데이터가 32개로 구성되어 있음을 의미함\n",
    "        > MLP 모델 학습 시에 32개 데잍로 첫 번째 학습을 수행하고, <br>\n",
    "        > 그 다음 32개의 데이터를 이용해 두 번째로 학습\n",
    "    - $1\\,Mini\\,Batch = 32\\,datas$\n",
    "    - 1개의 Mini-Batch를 이용해 학습하는 횟수를 <span style=\"color:magenta\">iteration</span>\n",
    "    - 전체 데이터를 이용해 학습을 진행한 횟수 <span style=\"color:magenta\">Epoch</span>\n",
    "        ```text\n",
    "        예를 들어, 전체 데이터 10,000개, 1,000개의 데이터를 이용해 Mini-Batch를 구성한다면\n",
    "        1Epoch당 10회의 Interation이 발생\n",
    "        ```\n",
    "    - Mini-Batch의 데이터 개수(BATCH_SIZE)와 Epoch를 지정하면 Iteration은 전체 데이터 개수에서 BATCH_SIZE로 나눠준 몫 만큼 Interation 진행  \n",
    "<br>\n",
    "- **<sapn style=\"color:green\">Epoch</span>**\n",
    "    - Mini-Batch 1개 단위로 Back Propagation을 이용해 MLP의 가중값을 업데이트\n",
    "    - Epoch는 존재하고 있는 Mini-Batch를 전부 이용하는 횟수를 의미\n",
    "\n",
    "> 예시) Datas = 10000, BATCH_SIZE = 100, Epoch = 20 일 때 <br>\n",
    "> 한 Mini-Batch 당 100개의 데이터가 활용 되므로 iteration = 100 <br>\n",
    "> 1 Epoch 당 100개의 iteration이 존재하므로 (총 학습 횟수) = 20*100 = 2000"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3.MNIST 데이터 다운로드 (Train, Test split)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''3. MNIST 데이터 다운로드 (Train, Test split)'''\n",
    "train_dataset = datasets.MNIST(root = \"./data/MNIST\",\n",
    "                               train = True,\n",
    "                               download = True,\n",
    "                               transform = transforms.ToTensor())\n",
    "test_dataset = datasets.MNIST(root = \"./data/MNIST\",\n",
    "                              train = False,\n",
    "                              transform = transforms.ToTensor())\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
    "                                           batch_size = BATCH_SIZE,\n",
    "                                           shuffle = True)\n",
    "test_loader = torch.utils.data.DataLoader(dataset = test_dataset,\n",
    "                                          batch_size = BATCH_SIZE,\n",
    "                                          shuffle = True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "\n",
    "```python\n",
    "train_dataset = datasets.MNIST(root = \"./data/MNIST\",\n",
    "                               train = True,\n",
    "                               download = True,\n",
    "                               transform = transforms.ToTensor())\n",
    "```\n",
    "- MNIST Datasets Downloads\n",
    "    - `root` : 데이터 저장될 장소\n",
    "    - `train` : 학습 데이터 여부 (bool type)\n",
    "    - `download` : 인터넷 다운로드 여부 (bool type)\n",
    "    - `transform` : 이미지 데이터의 기본 전처리를 다운로드 시 진행\n",
    "        > `transform.ToTensor()`메서드로 tensor 형태로 변경  \n",
    "        > 픽셀 0~255 범위의 스칼라 값을 0~1 범위로 정규화 진행  \n",
    "        > ANN은 Input이 클수록 불안정 or 과적합의 경향이 있으므로 정규화 해줄 것\n",
    "<br><br>\n",
    "---\n",
    "\n",
    "```python\n",
    "train_loader = torch.utils.data.DataLoader(dataset = train_dataset,\n",
    "                                           batch_size = BATCH_SIZE,\n",
    "                                           shuffle = True)\n",
    "```\n",
    "- Dataset을 Mini-Batch 단위로 분리 지정 (BATCH_SIZE를 이용해 지정)\n",
    "- `BATCH_SIZE` 만큼 묶어 1개의 Mini-Batch를 구성하는 단계\n",
    "    - `dataset` : Mini-Batch 단위로 할당하고자 하는 데이터 셋을 지정\n",
    "    - `batch_size` : Mini-Batch 1개의 단위\n",
    "    - shuffle : Label에 규칙이 있음을 방지하기 위해 섞어 줌\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.데이터 확인하기(1)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train: torch.Size([32, 1, 28, 28])   type: <built-in method type of Tensor object at 0x000002DC5D6A60E0>\n",
      "y_train: torch.Size([32])   type: <built-in method type of Tensor object at 0x000002DC5D6A9450>\n"
     ]
    }
   ],
   "source": [
    "'''4. 데이터 확인하기 (1)'''\n",
    "for (X_train, y_train) in train_loader:\n",
    "    print(f\"X_train: {X_train.size()}   type: {X_train.type}\")\n",
    "    print(f\"y_train: {y_train.size()}   type: {y_train.type}\")\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **다운로드 후 Mini-Batch로 할당한 데이터의 개수와 형태를 확인**\n",
    "\n",
    "---\n",
    "\n",
    "- `X_train`: 32개의 데이터가 1개의 Mini-Batch 구성, 28x28의 픽셀 구성과, 채널이 1(Gray Scale:흑백)인 데이터\n",
    "- `y_train` : 32개의 이미지 데이터 각각 label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5.데이터 확인하기(2)\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 720x72 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "'''5. 데이터 확인하기(2)'''\n",
    "pltSize=1\n",
    "plt.figure(figsize=(10*pltSize,pltSize))\n",
    "for i in range(10):\n",
    "    plt.subplot(1, 10, i+1)\n",
    "    plt.axis('off')\n",
    "    plt.imshow(X_train[i, :, :, :].numpy().reshape(28, 28), cmap=\"gray_r\")\n",
    "    plt.title(f\"Class: {str(y_train[i].item())}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.MLP (Multi Layer Perceptron) 설계\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''6. MLP (Multi Layer Perceptron) 설계'''\n",
    "class Net(nn.Module):                       # PyTorch Module 내에 딥러닝 모델 관련 기본  함수를 포함하고 있는 nn.Module 클래스를 상속받는 Net 클래스 정의\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()         # nn.Module 메서드 상속\n",
    "        self.fc1 = nn.Linear(28*28, 512)    # Fisrt Fully Connected Layer : Input 크기 28*28*1 에 맞게 28*28 설정, Scond FCL이 512 input이므로 512 설정\n",
    "        self.fc2 = nn.Linear(512, 256)      # Second Fully Connected Layer : 노드 수 512개로 설정, Third FCL를 256의 노드 수로 설정할 것이므로 256 설정\n",
    "        self.fc3 = nn.Linear(256,10)        # Third Fully Connected Layer : 노드 수 256개 설정, Label 수에 맞게 끔 Output 10 설정\n",
    "        \n",
    "    def forward(self, x):                   # Net Class MLP Model의 Forward Propagation을 정의 (Output 계산까지의 과정 나열)\n",
    "        x = x.view(-1, 28*28)               # MLP 모델의 입력은 1차원 인데 MNIST Set은 28*28로 2차원이므로 1차원으로 변환 해주는 View 메서드 (2차원을 1차원으로 펼친다 : Flatten)\n",
    "        x = self.fc1(x)                     # __init__ 메서드를 이용해 First FCL에 1차원으로 펼친 이미지 데이터 통과\n",
    "        x = F.sigmoid(x)                    # torch.nn.functional에 정의된 비선형 활성화 함수 sigmoid() 적용하여 Second FLC의 Input 계산\n",
    "        x = self.fc2(x)                     # __init__ 메서드를 이용해 Second FCL에 sigmoid()로 활성화 된 Input data 통과\n",
    "        x - F.sigmoid(x)                    # torch.nn.functional에 정의된 비선형 활성화 함수 sigmoid() 적용하여 Third FLC의 Input 계산\n",
    "        x = self.fc3(x)                     # __init__ 메서드를 이용해 Third FCL에 sigmoid()로 활성화 된 Input data 통과\n",
    "        x = F.log_softmax(x, dim=1)         # torch.nn.functional 내의 log.softmax()를 이용해 최종 output 계산\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## **코드 과정 상세**\n",
    "\n",
    "---\n",
    "```python\n",
    "class Net(nn.Module):\n",
    "```\n",
    "- PyTorch Module 내에 딥러닝 모델 관련 기본  함수를 포함하고 있는 nn.Module 클래스를 상속받는 Net 클래스 정의\n",
    "<br><br>\n",
    "---\n",
    "\n",
    "```python\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(28*28, 512)\n",
    "        self.fc2 = nn.Linear(512, 256)\n",
    "        self.fc3 = nn.Linear(256,10)\n",
    "```\n",
    "- nn.Module 메서드 상속\n",
    "- Fisrt Fully Connected Layer : Input 크기 28*28*1 에 맞게 28*28 설정, Scond FCL이 512 input이므로 512 설정\n",
    "- Second Fully Connected Layer : 노드 수 512개로 설정, Third FCL를 256의 노드 수로 설정할 것이므로 256 설정\n",
    "- Third Fully Connected Layer : 노드 수 256개 설정, Label 수에 맞게 끔 Output 10 설정\n",
    "<br><br>  \n",
    "---\n",
    "\n",
    "```python\n",
    "    def forward(self, x):\n",
    "        x = x.view(-1, 28*28)\n",
    "        x = self.fc1(x)\n",
    "        x = F.sigmoid(x)\n",
    "        x = self.fc2(x)\n",
    "        x - F.sigmoid(x)\n",
    "        x = self.fc3(x)\n",
    "        x = F.log_softmax(x, dim=1)\n",
    "        return x\n",
    "```\n",
    "- Net Class MLP Model의 Forward Propagation을 정의 (Output 계산까지의 과정 나열)\n",
    "- MLP 모델의 입력은 1차원 인데 MNIST Set은 28*28로 2차원이므로 1차원으로 변환 해주는 View 메서드 (2차원을 1차원으로 펼친다 : Flatten)\n",
    "- `__init__` 메서드를 이용해 First FCL에 1차원으로 펼친 이미지 데이터 통과\n",
    "- `torch.nn.functional`에 정의된 비선형 활성화 함수 `sigmoid()` 적용하여 Second FLC의 Input 계산\n",
    "- `__init__` 메서드를 이용해 Second FCL에 `sigmoid()`로 활성화 된 Input data 통과\n",
    "- `torch.nn.functional`에 정의된 비선형 활성화 함수 `sigmoid()` 적용하여 Third FLC의 Input 계산\n",
    "- `__init__` 메서드를 이용해 Third FCL에 `sigmoid()`로 활성화 된 Input data 통과\n",
    "- `torch.nn.functional` 내의 `log.softmax()`를 이용해 최종 output 계산\n",
    "    > `softmax()`가 아닌 `log.softmax()`를 사용하는 이유는 MLP 모델이 Back Propagation으로 학습을 진행할 때  \n",
    "    > Loss 값에 대한 Gradient 값을 좀 더 원활하게 계산할 수 있기 때문  \n",
    "    > log 함수 그래프의 기울기가 부드럽게 변화하는 것을 보면 직관적 이해 가능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7.Optimizer, Objective Function 설정\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (fc1): Linear(in_features=784, out_features=512, bias=True)\n",
      "  (fc2): Linear(in_features=512, out_features=256, bias=True)\n",
      "  (fc3): Linear(in_features=256, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "'''7. Optimizer, Objective Function 설정'''\n",
    "model = Net().to(DEVICE)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=.01, momentum=.5)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### **코드 과정 상세**\n",
    "---\n",
    "```python\n",
    "model = Net().to(DEVICE)\n",
    "```\n",
    "- MLP 모델에 장비 할당\n",
    "<br><br>\n",
    "---\n",
    "\n",
    "```python\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=.01, momentum=.5)\n",
    "```\n",
    "- Back Propagation을 이용해 파라미터 업데이트 시에 사용하는 Optimizer 정의\n",
    "- SGD 알고리즘을 사용하고 `learning rate=0.01`, optimizer의 관성을 나타내는 `momentum=0.5` 부여\n",
    "<br><br>\n",
    "---\n",
    "\n",
    "```python\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "```\n",
    "- output 값과 One-Hot Encoding의 값의 Loss는 `CrossEntropy`를 이용해 계산"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8.MLP 모델 학습 시 학습 데이터에 대한 모델 성능을 확인하는 함수 정의\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''8. MLP 모델 학습 시 학습 데이터에 대한 모델 성능을 확인하는 함수 정의'''\n",
    "def train(model, train_loader, optimizer, log_interval):\n",
    "    model.train()\n",
    "    for batch_idx, (image, label) in enumerate(train_loader):\n",
    "        image = image.to(DEVICE)\n",
    "        label = label.to(DEVICE)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(image)\n",
    "        loss = criterion(output, label)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        \n",
    "        if batch_idx % log_interval == 0:\n",
    "            print(\"Train Epoch: {} [{}/{}({:.0f}%)]\\tTrain Loss: {:.6f}\".format(Epoch, batch_idx*len(image),\n",
    "                                                                                 len(train_loader.dataset), 100.*batch_idx/len(train_loader),\n",
    "                                                                                 loss.item()))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9.학습 과정에서 검증 데이터에 대한 모델의 성능을 확인하는 함수 정의\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, test_loader):\n",
    "    model.eval()\n",
    "    test_loss=0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for image, label in test_loader:\n",
    "            image = image.to(DEVICE)\n",
    "            label = label.to(DEVICE)\n",
    "            output = model(image)\n",
    "            test_loss += criterion(output, label).item()\n",
    "            prediction = output.max(1, keepdim=True)[1]\n",
    "            correct += prediction.eq(label.view_as(prediction)).sum().item()\n",
    "    test_loss /= len(test_loader.dataset)\n",
    "    test_accuracy = 100. * correct / len(test_loader.dataset)\n",
    "    return test_loss, test_accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10.MLP 학습을 실행하면서 Train, Test set의 Loss 및 Test set Accuracy 확인\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\yunjc\\anaconda3\\envs\\dl_env\\lib\\site-packages\\torch\\nn\\functional.py:1806: UserWarning: nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\n",
      "  warnings.warn(\"nn.functional.sigmoid is deprecated. Use torch.sigmoid instead.\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Epoch: 1 [0/60000(0%)]\tTrain Loss: 2.298774\n",
      "Train Epoch: 1 [6400/60000(11%)]\tTrain Loss: 2.196892\n",
      "Train Epoch: 1 [12800/60000(21%)]\tTrain Loss: 2.150587\n",
      "Train Epoch: 1 [19200/60000(32%)]\tTrain Loss: 1.734314\n",
      "Train Epoch: 1 [25600/60000(43%)]\tTrain Loss: 1.296788\n",
      "Train Epoch: 1 [32000/60000(53%)]\tTrain Loss: 1.087169\n",
      "Train Epoch: 1 [38400/60000(64%)]\tTrain Loss: 0.582945\n",
      "Train Epoch: 1 [44800/60000(75%)]\tTrain Loss: 0.681578\n",
      "Train Epoch: 1 [51200/60000(85%)]\tTrain Loss: 0.384922\n",
      "Train Epoch: 1 [57600/60000(96%)]\tTrain Loss: 0.380759\n",
      "\n",
      "[EPOCH: 1], \tTest Loss: 0.0170, \tTest Accuracy: 84.06 % \n",
      "\n",
      "Train Epoch: 2 [0/60000(0%)]\tTrain Loss: 0.649623\n",
      "Train Epoch: 2 [6400/60000(11%)]\tTrain Loss: 0.696271\n",
      "Train Epoch: 2 [12800/60000(21%)]\tTrain Loss: 0.468957\n",
      "Train Epoch: 2 [19200/60000(32%)]\tTrain Loss: 0.282265\n",
      "Train Epoch: 2 [25600/60000(43%)]\tTrain Loss: 0.267103\n",
      "Train Epoch: 2 [32000/60000(53%)]\tTrain Loss: 0.305264\n",
      "Train Epoch: 2 [38400/60000(64%)]\tTrain Loss: 0.328886\n",
      "Train Epoch: 2 [44800/60000(75%)]\tTrain Loss: 0.238402\n",
      "Train Epoch: 2 [51200/60000(85%)]\tTrain Loss: 0.449399\n",
      "Train Epoch: 2 [57600/60000(96%)]\tTrain Loss: 0.459443\n",
      "\n",
      "[EPOCH: 2], \tTest Loss: 0.0119, \tTest Accuracy: 89.08 % \n",
      "\n",
      "Train Epoch: 3 [0/60000(0%)]\tTrain Loss: 0.255273\n",
      "Train Epoch: 3 [6400/60000(11%)]\tTrain Loss: 0.188675\n",
      "Train Epoch: 3 [12800/60000(21%)]\tTrain Loss: 0.218540\n",
      "Train Epoch: 3 [19200/60000(32%)]\tTrain Loss: 0.656251\n",
      "Train Epoch: 3 [25600/60000(43%)]\tTrain Loss: 0.171224\n",
      "Train Epoch: 3 [32000/60000(53%)]\tTrain Loss: 0.328788\n",
      "Train Epoch: 3 [38400/60000(64%)]\tTrain Loss: 0.505909\n",
      "Train Epoch: 3 [44800/60000(75%)]\tTrain Loss: 0.318621\n",
      "Train Epoch: 3 [51200/60000(85%)]\tTrain Loss: 0.259183\n",
      "Train Epoch: 3 [57600/60000(96%)]\tTrain Loss: 0.443423\n",
      "\n",
      "[EPOCH: 3], \tTest Loss: 0.0106, \tTest Accuracy: 90.37 % \n",
      "\n",
      "Train Epoch: 4 [0/60000(0%)]\tTrain Loss: 0.488254\n",
      "Train Epoch: 4 [6400/60000(11%)]\tTrain Loss: 0.610733\n",
      "Train Epoch: 4 [12800/60000(21%)]\tTrain Loss: 0.126490\n",
      "Train Epoch: 4 [19200/60000(32%)]\tTrain Loss: 0.194067\n",
      "Train Epoch: 4 [25600/60000(43%)]\tTrain Loss: 0.132881\n",
      "Train Epoch: 4 [32000/60000(53%)]\tTrain Loss: 0.221347\n",
      "Train Epoch: 4 [38400/60000(64%)]\tTrain Loss: 0.323085\n",
      "Train Epoch: 4 [44800/60000(75%)]\tTrain Loss: 0.096254\n",
      "Train Epoch: 4 [51200/60000(85%)]\tTrain Loss: 0.129299\n",
      "Train Epoch: 4 [57600/60000(96%)]\tTrain Loss: 0.195045\n",
      "\n",
      "[EPOCH: 4], \tTest Loss: 0.0099, \tTest Accuracy: 91.11 % \n",
      "\n",
      "Train Epoch: 5 [0/60000(0%)]\tTrain Loss: 0.237656\n",
      "Train Epoch: 5 [6400/60000(11%)]\tTrain Loss: 0.232376\n",
      "Train Epoch: 5 [12800/60000(21%)]\tTrain Loss: 0.495509\n",
      "Train Epoch: 5 [19200/60000(32%)]\tTrain Loss: 0.318922\n",
      "Train Epoch: 5 [25600/60000(43%)]\tTrain Loss: 0.766412\n",
      "Train Epoch: 5 [32000/60000(53%)]\tTrain Loss: 0.125737\n",
      "Train Epoch: 5 [38400/60000(64%)]\tTrain Loss: 0.233892\n",
      "Train Epoch: 5 [44800/60000(75%)]\tTrain Loss: 0.205133\n",
      "Train Epoch: 5 [51200/60000(85%)]\tTrain Loss: 0.264825\n",
      "Train Epoch: 5 [57600/60000(96%)]\tTrain Loss: 0.184529\n",
      "\n",
      "[EPOCH: 5], \tTest Loss: 0.0093, \tTest Accuracy: 91.36 % \n",
      "\n",
      "Train Epoch: 6 [0/60000(0%)]\tTrain Loss: 0.189095\n",
      "Train Epoch: 6 [6400/60000(11%)]\tTrain Loss: 0.144505\n",
      "Train Epoch: 6 [12800/60000(21%)]\tTrain Loss: 0.293383\n",
      "Train Epoch: 6 [19200/60000(32%)]\tTrain Loss: 0.190502\n",
      "Train Epoch: 6 [25600/60000(43%)]\tTrain Loss: 0.154618\n",
      "Train Epoch: 6 [32000/60000(53%)]\tTrain Loss: 0.311370\n",
      "Train Epoch: 6 [38400/60000(64%)]\tTrain Loss: 0.127694\n",
      "Train Epoch: 6 [44800/60000(75%)]\tTrain Loss: 0.356421\n",
      "Train Epoch: 6 [51200/60000(85%)]\tTrain Loss: 0.278351\n",
      "Train Epoch: 6 [57600/60000(96%)]\tTrain Loss: 0.174209\n",
      "\n",
      "[EPOCH: 6], \tTest Loss: 0.0091, \tTest Accuracy: 91.68 % \n",
      "\n",
      "Train Epoch: 7 [0/60000(0%)]\tTrain Loss: 0.086141\n",
      "Train Epoch: 7 [6400/60000(11%)]\tTrain Loss: 0.313710\n",
      "Train Epoch: 7 [12800/60000(21%)]\tTrain Loss: 0.477272\n",
      "Train Epoch: 7 [19200/60000(32%)]\tTrain Loss: 0.275203\n",
      "Train Epoch: 7 [25600/60000(43%)]\tTrain Loss: 0.290561\n",
      "Train Epoch: 7 [32000/60000(53%)]\tTrain Loss: 0.281972\n",
      "Train Epoch: 7 [38400/60000(64%)]\tTrain Loss: 0.148133\n",
      "Train Epoch: 7 [44800/60000(75%)]\tTrain Loss: 0.084190\n",
      "Train Epoch: 7 [51200/60000(85%)]\tTrain Loss: 0.312777\n",
      "Train Epoch: 7 [57600/60000(96%)]\tTrain Loss: 0.343361\n",
      "\n",
      "[EPOCH: 7], \tTest Loss: 0.0092, \tTest Accuracy: 91.56 % \n",
      "\n",
      "Train Epoch: 8 [0/60000(0%)]\tTrain Loss: 0.559501\n",
      "Train Epoch: 8 [6400/60000(11%)]\tTrain Loss: 0.171665\n",
      "Train Epoch: 8 [12800/60000(21%)]\tTrain Loss: 0.168861\n",
      "Train Epoch: 8 [19200/60000(32%)]\tTrain Loss: 0.419465\n",
      "Train Epoch: 8 [25600/60000(43%)]\tTrain Loss: 0.332973\n",
      "Train Epoch: 8 [32000/60000(53%)]\tTrain Loss: 0.209662\n",
      "Train Epoch: 8 [38400/60000(64%)]\tTrain Loss: 0.246532\n",
      "Train Epoch: 8 [44800/60000(75%)]\tTrain Loss: 0.089010\n",
      "Train Epoch: 8 [51200/60000(85%)]\tTrain Loss: 0.247484\n",
      "Train Epoch: 8 [57600/60000(96%)]\tTrain Loss: 0.904261\n",
      "\n",
      "[EPOCH: 8], \tTest Loss: 0.0089, \tTest Accuracy: 92.07 % \n",
      "\n",
      "Train Epoch: 9 [0/60000(0%)]\tTrain Loss: 0.112684\n",
      "Train Epoch: 9 [6400/60000(11%)]\tTrain Loss: 0.253701\n",
      "Train Epoch: 9 [12800/60000(21%)]\tTrain Loss: 0.156400\n",
      "Train Epoch: 9 [19200/60000(32%)]\tTrain Loss: 0.470463\n",
      "Train Epoch: 9 [25600/60000(43%)]\tTrain Loss: 0.362659\n",
      "Train Epoch: 9 [32000/60000(53%)]\tTrain Loss: 0.410067\n",
      "Train Epoch: 9 [38400/60000(64%)]\tTrain Loss: 0.393715\n",
      "Train Epoch: 9 [44800/60000(75%)]\tTrain Loss: 0.122378\n",
      "Train Epoch: 9 [51200/60000(85%)]\tTrain Loss: 0.617324\n",
      "Train Epoch: 9 [57600/60000(96%)]\tTrain Loss: 0.154554\n",
      "\n",
      "[EPOCH: 9], \tTest Loss: 0.0090, \tTest Accuracy: 91.74 % \n",
      "\n",
      "Train Epoch: 10 [0/60000(0%)]\tTrain Loss: 0.056836\n",
      "Train Epoch: 10 [6400/60000(11%)]\tTrain Loss: 0.214397\n",
      "Train Epoch: 10 [12800/60000(21%)]\tTrain Loss: 0.096056\n",
      "Train Epoch: 10 [19200/60000(32%)]\tTrain Loss: 0.448895\n",
      "Train Epoch: 10 [25600/60000(43%)]\tTrain Loss: 0.106789\n",
      "Train Epoch: 10 [32000/60000(53%)]\tTrain Loss: 0.151988\n",
      "Train Epoch: 10 [38400/60000(64%)]\tTrain Loss: 0.148428\n",
      "Train Epoch: 10 [44800/60000(75%)]\tTrain Loss: 0.050763\n",
      "Train Epoch: 10 [51200/60000(85%)]\tTrain Loss: 0.191736\n",
      "Train Epoch: 10 [57600/60000(96%)]\tTrain Loss: 0.159649\n",
      "\n",
      "[EPOCH: 10], \tTest Loss: 0.0087, \tTest Accuracy: 91.93 % \n",
      "\n"
     ]
    }
   ],
   "source": [
    "for Epoch in range(1, EPOCHS+1):\n",
    "    train(model, train_loader, optimizer, log_interval=200)\n",
    "    test_loss, test_accuracy = evaluate(model, test_loader)\n",
    "    print(\"\\n[EPOCH: {}], \\tTest Loss: {:.4f}, \\tTest Accuracy: {:.2f} % \\n\".\n",
    "    format(Epoch, test_loss, test_accuracy))"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "8aee22797df4b788837c069f0ef8574f3e7e1be82db3fea6d988500a32afa623"
  },
  "kernelspec": {
   "display_name": "Python 3.8.8 64-bit ('dl_env': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
